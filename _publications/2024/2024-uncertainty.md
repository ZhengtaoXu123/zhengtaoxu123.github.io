---
title:          "Confronting Verbalized Uncertainty: Understanding How AIâ€™s Uncertainty Influences Users in AI-Assisted Decision-Making"
date:           2024-10-12
selected:       false
pub:            "International Journal of Human-Computer Studies (IJHCS)"
# pub_pre:        "Submitted to "
pub_post:       "(Under review)"
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
# pub_date:       "2024"

abstract: >-
  Due to the human-like nature, large language models (LLMs) often output expressions of uncertainty such as <strong>"I'm sure that [...]"}</strong> or <strong>"It could be [...]"</strong>. However, few studies have explored how these expressions impact human users. To address this gap, we conducted a between-condition study (N = 156). Using the popular word guessing game Codenames, we simulated how LLMs assist humans in decision-making and explored the effects of different levels of verbalized uncertainty on user trust, satisfaction, and performance. Our results showed that medium uncertainty consistently outperforms both high and low uncertainty on user trust, satisfaction, and performance. Additionally, our results also revealed varying impacts of uncertainty and accuracy at different levels, and the emotional mediation between uncertainty and satisfaction, which deepened our understanding of how different levels of verbalized uncertainty affect human users. This study offers important implications for the future design of LLMs, recommending balanced expressions of uncertainty and suggesting adaptive strategies to express uncertainty based on the AI's capabilities or the task complexity.
cover:          /assets/images/covers/uncertainty.png
authors:
  - Zhengtao Xu
  - Tianqi Song
  - Yi-Chieh Lee
---
